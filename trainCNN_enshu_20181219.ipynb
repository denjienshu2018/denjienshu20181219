{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 必要ライブラリをインポート\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 初期値を設定する。\n",
    "batch_size = 100\n",
    "training_epochs = 1000\n",
    "display_epochs = 10\n",
    "length_of_side = 0.1 # 立方体の一片の長さ(m)\n",
    "i_max = 10 # 電荷の最大値"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickleファイルを読み込む。\n",
    "dataset_elecs, dataset_fields = pickle.load(open('dataset20181219.pickle', 'rb'))\n",
    "\n",
    "dataset_size = len(dataset_elecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "課題6:dataset_elecs, dataset_fieldsの規格化(0~1の値にする)を行う。\n",
    "dataset_elecs[:, 0, :]をi_maxで割る。\n",
    "dataset_elecs[:, 1:, :]をlength_of_sideで割る。\n",
    "dataset_fieldsの要素全てを最小値で引き、その後最大値で割る。\n",
    "\"\"\"\n",
    "############## 課題6 ################\n",
    "\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "課題7:dataset_elecs, dataset_fieldsをそれぞれfloat型に変換する。\n",
    "その後(10000, 2 * 3), (10000, 11 * 11 * 3 * 6)にreshapeする。\n",
    "\"\"\"\n",
    "############## 課題7 ################\n",
    "\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "課題8:データセットのうち1000をテストデータ、残りを学習用にする。\n",
    "学習用データをelecs_train, fields_train\n",
    "テストデータをelecs_test, fields_test\n",
    "という変数名とする。\n",
    "\"\"\"\n",
    "############## 課題8 ################\n",
    "\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# graphの構築\n",
    "# placeholderの定義\n",
    "x = tf.placeholder(\"float\", shape=[None, 11 * 11 * 3 * 6])\n",
    "y_ = tf.placeholder(\"float\", shape=[None, 6])\n",
    "\n",
    "# 荷重作成\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# バイアス作成\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 畳み込み処理を定義\n",
    "def conv2d_pad(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# プーリング処理を定義\n",
    "def max_pool_2_2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\"\"\"\n",
    "課題9:tensorflowグラフを構築する。\n",
    "以下の実装例でも動作しますが、\n",
    "時間があれば自身でフィルタの大きさ、特徴マップの大きさ、隠れ層の大きさ、畳み込み層を増やすなど工夫してください。\n",
    "\"\"\"\n",
    "############## 課題9 ################\n",
    "# 畳み込み層1\n",
    "W_conv1 = weight_variable([3, 3, 18, 256])\n",
    "b_conv1 = bias_variable([256])\n",
    "x_image = tf.reshape(x, [-1, 11, 11, 18])\n",
    "h_conv1 = tf.nn.relu(conv2d_pad(x_image, W_conv1) + b_conv1)\n",
    "# プーリング層1\n",
    "h_pool1 = max_pool_2_2(h_conv1)\n",
    "\n",
    "# 畳み込み層2\n",
    "W_conv2 = weight_variable([3, 3, 256, 256])\n",
    "b_conv2 = bias_variable([256])\n",
    "h_conv2 = tf.nn.relu(conv2d_pad(h_pool1, W_conv2) + b_conv2)\n",
    "# プーリング層2\n",
    "h_pool2 = max_pool_2_2(h_conv2)\n",
    "\n",
    "# 全結合層1\n",
    "W_fc1 = weight_variable([256*3*3, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_flat = tf.reshape(h_pool2, [-1, 256*3*3])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# ドロップアウト\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 全結合層2\n",
    "W_fc2 = weight_variable([1024, 6])\n",
    "b_fc2 = bias_variable([6])\n",
    "y_out = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# 学習誤差を求める\n",
    "loss = tf.reduce_mean(tf.square(y_ - y_out))\n",
    "\n",
    "# 最適化処理\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# セッション開始\n",
    "with tf.Session() as sess:\n",
    "    # グラフの保存クラス\n",
    "    saver = tf.train.Saver()\n",
    "    # グラフの初期化\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "    # 学習済みグラフの読み込み\n",
    "    # saver.restore(sess, \"./20181219model\")\n",
    "    \n",
    "    # training_epoch回学習を行う\n",
    "    for i in range(training_epochs):\n",
    "        \"\"\"\n",
    "        課題10:fields_train, charges_trainをbatch_sizeずつ取り出すし、batch, outputとする。\n",
    "        batch:(batch_size, 11*11*3*6)\n",
    "        output:(batch_size, 6)\n",
    "        となる。\n",
    "        placeholderのx, y_をそれぞれbatch, outputとしてグラフのtrain_stepを呼び出すことで学習を行う。\n",
    "        \"\"\"\n",
    "        ############## 課題10 ################\n",
    "\n",
    "        #####################################\n",
    "        # display_epochsごとに学習経過を出力する。\n",
    "        if i%display_epochs == 0:\n",
    "            train_loss = 0.0\n",
    "            test_loss = 0.0\n",
    "            for k in range(0, elecs_train.shape[0], batch_size):\n",
    "                batch = fields_train[k:k+batch_size, :]\n",
    "                output = elecs_train[k:k+batch_size, :]\n",
    "                train_loss += loss.eval(session=sess, feed_dict={x: batch, y_: output, keep_prob: 1.0})\n",
    "            for k in range(0, elecs_test.shape[0], batch_size):\n",
    "                batch = fields_test[k:k+batch_size, :]\n",
    "                output = elecs_test[k:k+batch_size, :]\n",
    "                test_loss += loss.eval(session=sess, feed_dict={x: batch, y_: output, keep_prob: 1.0})\n",
    "            train_loss /= (dataset_size - 1000) / batch_size\n",
    "            test_loss /= 1000 / batch_size\n",
    "            print(\"training_finished:\" + str(i) + \"epochs\")\n",
    "            print(\"train_loss=\" + str(train_loss))\n",
    "            print(\"test_loss=\" + str(test_loss))\n",
    "    # 学習したモデルを保存する。\n",
    "    saver.save(sess, \"./20181219model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
